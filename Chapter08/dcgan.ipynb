{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eps=10\n",
    "bsize=32\n",
    "lrate=0.001\n",
    "lat_dimension=64\n",
    "image_sz=64\n",
    "chnls=1\n",
    "logging_intv=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANGenerator, self).__init__()\n",
    "        self.inp_sz = image_sz // 4\n",
    "        self.lin = nn.Linear(lat_dimension, 128 * self.inp_sz ** 2)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.up1 = nn.Upsample(scale_factor=2)\n",
    "        self.cn1 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128, 0.8)\n",
    "        self.rl1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.up2 = nn.Upsample(scale_factor=2)\n",
    "        self.cn2 = nn.Conv2d(128, 64, 3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64, 0.8)\n",
    "        self.rl2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.cn3 = nn.Conv2d(64, chnls, 3, stride=1, padding=1)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = x.view(x.shape[0], 128, self.inp_sz, self.inp_sz)\n",
    "        x = self.bn1(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.cn1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.rl1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.cn2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.rl2(x)\n",
    "        x = self.cn3(x)\n",
    "        out = self.act(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANDiscriminator, self).__init__()\n",
    "\n",
    "        def disc_module(ip_chnls, op_chnls, bnorm=True):\n",
    "            mod = [nn.Conv2d(ip_chnls, op_chnls, 3, 2, 1), \n",
    "                   nn.LeakyReLU(0.2, inplace=True), \n",
    "                   nn.Dropout2d(0.25)]\n",
    "            if bnorm:\n",
    "                mod += [nn.BatchNorm2d(op_chnls, 0.8)]\n",
    "            return mod\n",
    "\n",
    "        self.disc_model = nn.Sequential(\n",
    "            *disc_module(chnls, 16, bnorm=False),\n",
    "            *disc_module(16, 32),\n",
    "            *disc_module(32, 64),\n",
    "            *disc_module(64, 128),\n",
    "        )\n",
    "\n",
    "        # width and height of the down-sized image\n",
    "        ds_size = image_sz // 2 ** 4\n",
    "        self.adverse_lyr = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.disc_model(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        out = self.adverse_lyr(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the discriminator and generator models\n",
    "gen = GANGenerator()\n",
    "disc = GANDiscriminator()\n",
    "\n",
    "# define the loss metric\n",
    "adv_loss_func = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset and corresponding dataloader\n",
    "dloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"./data/mnist/\",\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize((image_sz, image_sz)), \n",
    "             transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=bsize,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# define the optimization schedule for both G and D\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lrate)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./images_mnist\", exist_ok=True)\n",
    "\n",
    "for ep in range(num_eps):\n",
    "    for idx, (images, _) in enumerate(dloader):\n",
    "\n",
    "        # generate grounnd truths for real and fake images\n",
    "        good_img = Variable(torch.FloatTensor(images.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        bad_img = Variable(torch.FloatTensor(images.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # get a real image\n",
    "        actual_images = Variable(images.type(torch.FloatTensor))\n",
    "\n",
    "        # train the generator model\n",
    "        opt_gen.zero_grad()\n",
    "\n",
    "        # generate a batch of images based on random noise as input\n",
    "        noise = Variable(torch.FloatTensor(np.random.normal(0, 1, (images.shape[0], lat_dimension))))\n",
    "        gen_images = gen(noise)\n",
    "\n",
    "        # generator model optimization - how well can it fool the discriminator\n",
    "        generator_loss = adv_loss_func(disc(gen_images), good_img)\n",
    "        generator_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # train the discriminator model\n",
    "        opt_disc.zero_grad()\n",
    "\n",
    "        # calculate discriminator loss as average of mistakes(losses) in confusing real images as fake and vice versa\n",
    "        actual_image_loss = adv_loss_func(disc(actual_images), good_img)\n",
    "        fake_image_loss = adv_loss_func(disc(gen_images.detach()), bad_img)\n",
    "        discriminator_loss = (actual_image_loss + fake_image_loss) / 2\n",
    "\n",
    "        # discriminator model optimization\n",
    "        discriminator_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        batches_completed = ep * len(dloader) + idx\n",
    "        if batches_completed % logging_intv == 0:\n",
    "            print(f\"epoch number {ep} | batch number {idx} | generator loss = {generator_loss.item()} | discriminator loss = {discriminator_loss.item()}\")\n",
    "            save_image(gen_images.data[:25], f\"images_mnist/{batches_completed}.png\", nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
