{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cn1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.cn2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.dp1 = nn.Dropout2d(0.10)\n",
    "        self.dp2 = nn.Dropout2d(0.25)\n",
    "        self.fc1 = nn.Linear(4608, 64) # 4608 is basically 12 X 12 X 32\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.cn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dp1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc2(x)\n",
    "        op = F.log_softmax(x, dim=1)\n",
    "        return op\n",
    "    \n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_MODEL = \"./convnet.pth\"\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.ConvNet,\n",
       "      %x.1 : Tensor):\n",
       "  %51 : Function = prim::Constant[name=\"log_softmax\"]()\n",
       "  %49 : int = prim::Constant[value=3]()\n",
       "  %40 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %33 : int = prim::Constant[value=-1]()\n",
       "  %26 : Function = prim::Constant[name=\"_max_pool2d\"]()\n",
       "  %20 : int = prim::Constant[value=0]()\n",
       "  %19 : None = prim::Constant()\n",
       "  %14 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %7 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %6 : bool = prim::Constant[value=0]()\n",
       "  %17 : int = prim::Constant[value=2]() # <ipython-input-2-936a1c5cab85>:16:28\n",
       "  %32 : int = prim::Constant[value=1]() # <ipython-input-2-936a1c5cab85>:18:29\n",
       "  %2 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"cn1\"](%self)\n",
       "  %x.3 : Tensor = prim::CallMethod[name=\"forward\"](%2, %x.1) # <ipython-input-2-936a1c5cab85>:12:12\n",
       "  %x.5 : Tensor = prim::CallFunction(%7, %x.3, %6) # <ipython-input-2-936a1c5cab85>:13:12\n",
       "  %9 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name=\"cn2\"](%self)\n",
       "  %x.7 : Tensor = prim::CallMethod[name=\"forward\"](%9, %x.5) # <ipython-input-2-936a1c5cab85>:14:12\n",
       "  %x.9 : Tensor = prim::CallFunction(%14, %x.7, %6) # <ipython-input-2-936a1c5cab85>:15:12\n",
       "  %18 : int[] = prim::ListConstruct(%17, %17)\n",
       "  %21 : int[] = prim::ListConstruct(%20, %20)\n",
       "  %23 : int[] = prim::ListConstruct(%32, %32)\n",
       "  %x.11 : Tensor = prim::CallFunction(%26, %x.9, %18, %19, %21, %23, %6, %6) # <ipython-input-2-936a1c5cab85>:16:12\n",
       "  %28 : __torch__.torch.nn.modules.dropout.Dropout2d = prim::GetAttr[name=\"dp1\"](%self)\n",
       "  %x.13 : Tensor = prim::CallMethod[name=\"forward\"](%28, %x.11) # <ipython-input-2-936a1c5cab85>:17:12\n",
       "  %x.15 : Tensor = aten::flatten(%x.13, %32, %33) # <ipython-input-2-936a1c5cab85>:18:12\n",
       "  %35 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc1\"](%self)\n",
       "  %x.17 : Tensor = prim::CallMethod[name=\"forward\"](%35, %x.15) # <ipython-input-2-936a1c5cab85>:19:12\n",
       "  %x.19 : Tensor = prim::CallFunction(%40, %x.17, %6) # <ipython-input-2-936a1c5cab85>:20:12\n",
       "  %42 : __torch__.torch.nn.modules.dropout.___torch_mangle_2.Dropout2d = prim::GetAttr[name=\"dp2\"](%self)\n",
       "  %x.21 : Tensor = prim::CallMethod[name=\"forward\"](%42, %x.19) # <ipython-input-2-936a1c5cab85>:21:12\n",
       "  %45 : __torch__.torch.nn.modules.linear.___torch_mangle_3.Linear = prim::GetAttr[name=\"fc2\"](%self)\n",
       "  %x.23 : Tensor = prim::CallMethod[name=\"forward\"](%45, %x.21) # <ipython-input-2-936a1c5cab85>:22:12\n",
       "  %op.1 : Tensor = prim::CallFunction(%51, %x.23, %32, %49, %19) # <ipython-input-2-936a1c5cab85>:23:13\n",
       "  return (%op.1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  _0 = __torch__.torch.nn.functional.___torch_mangle_12.relu\n",
      "  _1 = __torch__.torch.nn.functional._max_pool2d\n",
      "  _2 = __torch__.torch.nn.functional.___torch_mangle_13.relu\n",
      "  _3 = __torch__.torch.nn.functional.log_softmax\n",
      "  x0 = (self.cn1).forward(x, )\n",
      "  x1 = __torch__.torch.nn.functional.relu(x0, False, )\n",
      "  x2 = (self.cn2).forward(x1, )\n",
      "  x3 = _0(x2, False, )\n",
      "  x4 = _1(x3, [2, 2], None, [0, 0], [1, 1], False, False, )\n",
      "  x5 = (self.dp1).forward(x4, )\n",
      "  x6 = torch.flatten(x5, 1, -1)\n",
      "  x7 = (self.fc1).forward(x6, )\n",
      "  x8 = _2(x7, False, )\n",
      "  x9 = (self.dp2).forward(x8, )\n",
      "  x10 = (self.fc2).forward(x9, )\n",
      "  return _3(x10, 1, 3, None, )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scripted_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(scripted_model, 'scripted_convnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_scripted_model = torch.jit.load('scripted_convnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"./digit_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(image):\n",
    "    gray_image = transforms.functional.to_grayscale(image)\n",
    "    resized_image = transforms.functional.resize(gray_image, (28, 28))\n",
    "    input_image_tensor = transforms.functional.to_tensor(resized_image)\n",
    "    input_image_tensor_norm = transforms.functional.normalize(input_image_tensor, (0.1302,), (0.3069,))\n",
    "    return input_image_tensor_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = image_to_tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3505e+00, -1.2089e+01, -2.2391e-03, -8.9248e+00, -9.8197e+00,\n",
       "         -1.3350e+01, -9.0460e+00, -1.4492e+01, -6.3023e+00, -1.2283e+01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_scripted_model(input_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3505e+00, -1.2089e+01, -2.2391e-03, -8.9248e+00, -9.8197e+00,\n",
       "         -1.3350e+01, -9.0460e+00, -1.4492e+01, -6.3023e+00, -1.2283e+01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_tensor.unsqueeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
