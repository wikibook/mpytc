{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cn1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.cn2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.dp1 = nn.Dropout2d(0.10)\n",
    "        self.dp2 = nn.Dropout2d(0.25)\n",
    "        self.fc1 = nn.Linear(4608, 64) # 4608 is basically 12 X 12 X 32\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.cn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dp1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc2(x)\n",
    "        op = F.log_softmax(x, dim=1)\n",
    "        return op\n",
    "    \n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_MODEL = \"./convnet.pth\"\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_input = torch.ones(1, 1, 28, 28)\n",
    "traced_model = torch.jit.trace(model, demo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.torch.nn.modules.module.___torch_mangle_6.Module,\n",
       "      %input.1 : Float(1, 1, 28, 28)):\n",
       "  %113 : __torch__.torch.nn.modules.module.___torch_mangle_5.Module = prim::GetAttr[name=\"fc2\"](%self.1)\n",
       "  %110 : __torch__.torch.nn.modules.module.___torch_mangle_3.Module = prim::GetAttr[name=\"dp2\"](%self.1)\n",
       "  %109 : __torch__.torch.nn.modules.module.___torch_mangle_4.Module = prim::GetAttr[name=\"fc1\"](%self.1)\n",
       "  %106 : __torch__.torch.nn.modules.module.___torch_mangle_2.Module = prim::GetAttr[name=\"dp1\"](%self.1)\n",
       "  %105 : __torch__.torch.nn.modules.module.___torch_mangle_1.Module = prim::GetAttr[name=\"cn2\"](%self.1)\n",
       "  %102 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"cn1\"](%self.1)\n",
       "  %120 : Tensor = prim::CallMethod[name=\"forward\"](%102, %input.1)\n",
       "  %input.3 : Float(1, 16, 26, 26) = aten::relu(%120) # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %121 : Tensor = prim::CallMethod[name=\"forward\"](%105, %input.3)\n",
       "  %input.5 : Float(1, 32, 24, 24) = aten::relu(%121) # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %61 : int = prim::Constant[value=2]() # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
       "  %62 : int = prim::Constant[value=2]() # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
       "  %63 : int[] = prim::ListConstruct(%61, %62)\n",
       "  %64 : int[] = prim::ListConstruct()\n",
       "  %65 : int = prim::Constant[value=0]() # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
       "  %66 : int = prim::Constant[value=0]() # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
       "  %67 : int[] = prim::ListConstruct(%65, %66)\n",
       "  %68 : int = prim::Constant[value=1]() # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
       "  %69 : int = prim::Constant[value=1]() # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
       "  %70 : int[] = prim::ListConstruct(%68, %69)\n",
       "  %71 : bool = prim::Constant[value=0]() # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
       "  %input.6 : Float(1, 32, 12, 12) = aten::max_pool2d(%input.5, %63, %64, %67, %70, %71) # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
       "  %122 : Tensor = prim::CallMethod[name=\"forward\"](%106, %input.6)\n",
       "  %76 : int = prim::Constant[value=1]() # <ipython-input-2-936a1c5cab85>:18:0\n",
       "  %77 : int = prim::Constant[value=-1]() # <ipython-input-2-936a1c5cab85>:18:0\n",
       "  %input.7 : Float(1, 4608) = aten::flatten(%122, %76, %77) # <ipython-input-2-936a1c5cab85>:18:0\n",
       "  %123 : Tensor = prim::CallMethod[name=\"forward\"](%109, %input.7)\n",
       "  %input.9 : Float(1, 64) = aten::relu(%123) # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %124 : Tensor = prim::CallMethod[name=\"forward\"](%110, %input.9)\n",
       "  %125 : Tensor = prim::CallMethod[name=\"forward\"](%113, %124)\n",
       "  %91 : int = prim::Constant[value=1]() # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1317:0\n",
       "  %92 : None = prim::Constant()\n",
       "  %93 : Float(1, 10) = aten::log_softmax(%125, %91, %92) # /Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1317:0\n",
       "  return (%93)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  _0 = self.fc2\n",
      "  _1 = self.dp2\n",
      "  _2 = self.fc1\n",
      "  _3 = self.dp1\n",
      "  _4 = self.cn2\n",
      "  input0 = torch.relu((self.cn1).forward(input, ))\n",
      "  input1 = torch.relu((_4).forward(input0, ))\n",
      "  input2 = torch.max_pool2d(input1, [2, 2], annotate(List[int], []), [0, 0], [1, 1], False)\n",
      "  input3 = torch.flatten((_3).forward(input2, ), 1, -1)\n",
      "  input4 = torch.relu((_2).forward(input3, ))\n",
      "  _5 = (_0).forward((_1).forward(input4, ), )\n",
      "  return torch.log_softmax(_5, 1, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(traced_model, 'traced_convnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_traced_model = torch.jit.load('traced_convnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"./digit_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(image):\n",
    "    gray_image = transforms.functional.to_grayscale(image)\n",
    "    resized_image = transforms.functional.resize(gray_image, (28, 28))\n",
    "    input_image_tensor = transforms.functional.to_tensor(resized_image)\n",
    "    input_image_tensor_norm = transforms.functional.normalize(input_image_tensor, (0.1302,), (0.3069,))\n",
    "    return input_image_tensor_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = image_to_tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3505e+00, -1.2089e+01, -2.2391e-03, -8.9248e+00, -9.8197e+00,\n",
       "         -1.3350e+01, -9.0460e+00, -1.4492e+01, -6.3023e+00, -1.2283e+01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_traced_model(input_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3505e+00, -1.2089e+01, -2.2391e-03, -8.9248e+00, -9.8197e+00,\n",
       "         -1.3350e+01, -9.0460e+00, -1.4492e+01, -6.3023e+00, -1.2283e+01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
