{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "        super(ConvNet, self).__init__()\n",
    "        num_conv_layers = trial.suggest_int(\"num_conv_layers\", 1, 4)\n",
    "        num_fc_layers = trial.suggest_int(\"num_fc_layers\", 1, 2)\n",
    "\n",
    "        self.layers = []\n",
    "        input_depth = 1 # grayscale image\n",
    "        for i in range(num_conv_layers):\n",
    "            output_depth = trial.suggest_int(f\"conv_depth_{i}\", 16, 64)\n",
    "            self.layers.append(nn.Conv2d(input_depth, output_depth, 3, 1))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            input_depth = output_depth\n",
    "        self.layers.append(nn.MaxPool2d(2))\n",
    "        p = trial.suggest_float(f\"conv_dropout_{i}\", 0.1, 0.4)\n",
    "        self.layers.append(nn.Dropout(p))\n",
    "        self.layers.append(nn.Flatten())\n",
    "\n",
    "        input_feat = self._get_flatten_shape()\n",
    "        for i in range(num_fc_layers):\n",
    "            output_feat = trial.suggest_int(f\"fc_output_feat_{i}\", 16, 64)\n",
    "            self.layers.append(nn.Linear(input_feat, output_feat))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            p = trial.suggest_float(f\"fc_dropout_{i}\", 0.1, 0.4)\n",
    "            self.layers.append(nn.Dropout(p))\n",
    "            input_feat = output_feat\n",
    "        self.layers.append(nn.Linear(input_feat, 10))\n",
    "        self.layers.append(nn.LogSoftmax(dim=1))\n",
    "        \n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "    \n",
    "    def _get_flatten_shape(self):\n",
    "        conv_model = nn.Sequential(*self.layers)\n",
    "        op_feat = conv_model(torch.rand(1, 1, 28, 28))\n",
    "        n_size = op_feat.data.view(1, -1).size(1)\n",
    "        return n_size\n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean and standard deviation values are calculated as the mean of all pixel values of all images in the training dataset\n",
    "train_ds = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1302,), (0.3069,))]))\n",
    "test_ds = datasets.MNIST('../data', train=False, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1302,), (0.3069,))]))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training and inference routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_dataloader, optim, epoch):\n",
    "    model.train()\n",
    "    for b_i, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optim.zero_grad()\n",
    "        pred_prob = model(X)\n",
    "        loss = F.nll_loss(pred_prob, y) # nll is the negative likelihood loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if b_i % 500 == 0:\n",
    "            print('epoch: {} [{}/{} ({:.0f}%)]\\t training loss: {:.6f}'.format(\n",
    "                epoch, b_i * len(X), len(train_dataloader.dataset),\n",
    "                100. * b_i / len(train_dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_dataloader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    success = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred_prob = model(X)\n",
    "            loss += F.nll_loss(pred_prob, y, reduction='sum').item()  # loss summed across the batch\n",
    "            pred = pred_prob.argmax(dim=1, keepdim=True)  # use argmax to get the most likely prediction\n",
    "            success += pred.eq(y.view_as(pred)).sum().item()\n",
    "\n",
    "    loss /= len(test_dataloader.dataset)\n",
    "    \n",
    "    accuracy = 100. * success / len(test_dataloader.dataset)\n",
    "\n",
    "    print('\\nTest dataset: Overall Loss: {:.4f}, Overall Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        loss, success, len(test_dataloader.dataset), accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define optimizer and model training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    model = ConvNet(trial)\n",
    "    opt_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"Adadelta\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-1, 5e-1, log=True)\n",
    "    optimizer = getattr(optim, opt_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(1, 3):\n",
    "        train(model, device, train_dataloader, optimizer, epoch)\n",
    "        accuracy = test(model, device, test_dataloader)\n",
    "        trial.report(accuracy, epoch)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 10:57:24,406]\u001b[0m A new study created in memory with name: mastering_pytorch\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [0/60000 (0%)]\t training loss: 2.306849\n",
      "epoch: 1 [16000/60000 (27%)]\t training loss: 2.304207\n",
      "epoch: 1 [32000/60000 (53%)]\t training loss: 2.312835\n",
      "epoch: 1 [48000/60000 (80%)]\t training loss: 2.299432\n",
      "\n",
      "Test dataset: Overall Loss: 2.3394, Overall Accuracy: 974/10000 (10%)\n",
      "\n",
      "epoch: 2 [0/60000 (0%)]\t training loss: 2.288115\n",
      "epoch: 2 [16000/60000 (27%)]\t training loss: 2.405160\n",
      "epoch: 2 [32000/60000 (53%)]\t training loss: 2.450139\n",
      "epoch: 2 [48000/60000 (80%)]\t training loss: 2.314060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 11:01:01,311]\u001b[0m Trial 0 finished with value: 10.32 and parameters: {'num_conv_layers': 1, 'num_fc_layers': 1, 'conv_depth_0': 29, 'conv_dropout_0': 0.33975460255509893, 'fc_output_feat_0': 63, 'fc_dropout_0': 0.28457195650592076, 'optimizer': 'Adam', 'lr': 0.4635077277229724}. Best is trial 0 with value: 10.32.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset: Overall Loss: 2.3260, Overall Accuracy: 1032/10000 (10%)\n",
      "\n",
      "epoch: 1 [0/60000 (0%)]\t training loss: 2.330881\n",
      "epoch: 1 [16000/60000 (27%)]\t training loss: 2.307726\n",
      "epoch: 1 [32000/60000 (53%)]\t training loss: 2.360138\n",
      "epoch: 1 [48000/60000 (80%)]\t training loss: 2.434959\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"mastering_pytorch\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100, timeout=2000)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"results: \")\n",
    "print(\"num_trials_conducted: \", len(study.trials))\n",
    "print(\"num_trials_pruned: \", len(pruned_trials))\n",
    "print(\"num_trials_completed: \", len(complete_trials))\n",
    "\n",
    "print(\"results from best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"accuracy: \", trial.value)\n",
    "print(\"hyperparameters: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
