{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(799)\n",
    "tkz = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "mdl = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "ln = 10\n",
    "cue = \"It will\"\n",
    "gen = tkz.encode(cue)\n",
    "ctx = torch.tensor([gen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will be interesting to see how the new system works out\n"
     ]
    }
   ],
   "source": [
    "prv=None\n",
    "for i in range(ln):\n",
    "    op, prv = mdl(ctx, past=prv)\n",
    "    tkn = torch.argmax(op[..., -1, :])\n",
    "\n",
    "    gen += [tkn.tolist()]\n",
    "    ctx = tkn.unsqueeze(0)\n",
    "\n",
    "seq = tkz.decode(gen)\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will be interesting to see how the new system\n"
     ]
    }
   ],
   "source": [
    "ip_ids = tkz.encode(cue, return_tensors='pt')\n",
    "op_greedy = mdl.generate(ip_ids, max_length=ln)\n",
    "seq = tkz.decode(op_greedy[0], skip_special_tokens=True)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will be interesting to\n",
      "It will be a long\n",
      "It will be a great\n"
     ]
    }
   ],
   "source": [
    "op_beam = mdl.generate(\n",
    "    ip_ids, \n",
    "    max_length=5, \n",
    "    num_beams=3, \n",
    "    num_return_sequences=3, \n",
    ")\n",
    "\n",
    "for op_beam_cur in op_beam:\n",
    "    print(tkz.decode(op_beam_cur, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will also be a\n",
      "It will be a long\n",
      "It will also be interesting\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    torch.manual_seed(i)\n",
    "    op = mdl.generate(\n",
    "        ip_ids, \n",
    "        do_sample=True, \n",
    "        max_length=5, \n",
    "        top_k=2\n",
    "    )\n",
    "\n",
    "    seq = tkz.decode(op[0], skip_special_tokens=True)\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will be interesting to\n",
      "It will be interesting to\n",
      "It will be interesting to\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    torch.manual_seed(i)\n",
    "    op_greedy = mdl.generate(ip_ids, max_length=5)\n",
    "    seq = tkz.decode(op_greedy[0], skip_special_tokens=True)\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will require work in\n",
      "It will be an interesting\n",
      "It will likely be important\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    torch.manual_seed(i)\n",
    "    op = mdl.generate(\n",
    "        ip_ids, \n",
    "        do_sample=True, \n",
    "        max_length=5, \n",
    "        top_p=0.75, \n",
    "        top_k=0\n",
    "    )\n",
    "\n",
    "    seq = tkz.decode(op[0], skip_special_tokens=True)\n",
    "    print(seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
