{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x129866730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Instructions:\n",
    "\n",
    "- You need to download the dataset from here: https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "- Then, you need to unzip the downloaded zipped file in the present working directory\n",
    "- That should result in a new folder named aclImdb under the present working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:00<00:00, 13570.44it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 14500.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews : 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read sentiments and reviews data from the text files\n",
    "review_list = []\n",
    "label_list = []\n",
    "for label in ['pos', 'neg']:\n",
    "    for fname in tqdm(os.listdir(f'./aclImdb/train/{label}/')):\n",
    "        if 'txt' not in fname:\n",
    "            continue\n",
    "        with open(os.path.join(f'./aclImdb/train/{label}/', fname), encoding=\"utf8\") as f:\n",
    "            review_list += [f.read()]\n",
    "            label_list += [label]\n",
    "print ('Number of reviews :', len(review_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:01<00:00, 13231.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 334691), ('and', 162228), ('a', 161940), ('of', 145326), ('to', 135042), ('is', 106855), ('in', 93028), ('it', 77099), ('i', 75719), ('this', 75190)]\n"
     ]
    }
   ],
   "source": [
    "# pre-processing review text\n",
    "review_list = [review.lower() for review in review_list]\n",
    "review_list = [''.join([letter for letter in review if letter not in punctuation]) for review in tqdm(review_list)]\n",
    "\n",
    "# accumulate all review texts together\n",
    "reviews_blob = ' '.join(review_list)\n",
    "\n",
    "# generate list of all words of all reviews\n",
    "review_words = reviews_blob.split()\n",
    "\n",
    "# get the word counts\n",
    "count_words = Counter(review_words)\n",
    "\n",
    "# sort words as per counts (decreasing order)\n",
    "total_review_words = len(review_words)\n",
    "sorted_review_words = count_words.most_common(total_review_words)\n",
    "\n",
    "print(sorted_review_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5), ('is', 6), ('in', 7), ('it', 8), ('i', 9), ('this', 10)]\n"
     ]
    }
   ],
   "source": [
    "# create word to integer (token) dictionary in order to encode text as numbers\n",
    "vocab_to_token = {word:idx+1 for idx, (word, count) in enumerate(sorted_review_words)}\n",
    "print(list(vocab_to_token.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for a movie that gets no respect there sure are a lot of memorable quotes listed for this gem imagine a movie where joe piscopo is actually funny maureen stapleton is a scene stealer the moroni character is an absolute scream watch for alan the skipper hale jr as a police sgt\n",
      "\n",
      "[15, 3, 17, 11, 201, 56, 1165, 47, 242, 23, 3, 168, 4, 891, 4325, 3513, 15, 10, 1514, 822, 3, 17, 112, 884, 14623, 6, 155, 161, 7307, 15816, 6, 3, 134, 20049, 1, 32064, 108, 6, 33, 1492, 1943, 103, 15, 1550, 1, 18993, 9055, 1809, 14, 3, 549, 6906]\n"
     ]
    }
   ],
   "source": [
    "reviews_tokenized = []\n",
    "for review in review_list:\n",
    "    word_to_token = [vocab_to_token[word] for word in review.split()]\n",
    "    reviews_tokenized.append(word_to_token)\n",
    "print(review_list[0])\n",
    "print()\n",
    "print (reviews_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode sentiments as 0 or 1\n",
    "encoded_label_list = [1 if label =='pos' else 0 for label in label_list]\n",
    "\n",
    "reviews_len = [len(review) for review in reviews_tokenized]\n",
    "\n",
    "reviews_tokenized = [reviews_tokenized[i] for i, l in enumerate(reviews_len) if l>0 ]\n",
    "encoded_label_list = np.array([encoded_label_list[i] for i, l in enumerate(reviews_len) if l> 0 ], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pad_sequence(reviews_tokenized, sequence_length):\n",
    "    ''' returns the tokenized review sequences padded with 0's or truncated to the sequence_length.\n",
    "    '''\n",
    "    padded_reviews = np.zeros((len(reviews_tokenized), sequence_length), dtype = int)\n",
    "    \n",
    "    for idx, review in enumerate(reviews_tokenized):\n",
    "        review_len = len(review)\n",
    "        \n",
    "        if review_len <= sequence_length:\n",
    "            zeroes = list(np.zeros(sequence_length-review_len))\n",
    "            new_sequence = zeroes+review\n",
    "        elif review_len > sequence_length:\n",
    "            new_sequence = review[0:sequence_length]\n",
    "        \n",
    "        padded_reviews[idx,:] = np.array(new_sequence)\n",
    "    \n",
    "    return padded_reviews\n",
    "\n",
    "sequence_length = 512\n",
    "padded_reviews = pad_sequence(reviews_tokenized=reviews_tokenized, sequence_length=sequence_length)\n",
    "\n",
    "plt.hist(reviews_len);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = 0.75\n",
    "train_X = padded_reviews[:int(train_val_split*len(padded_reviews))]\n",
    "train_y = encoded_label_list[:int(train_val_split*len(padded_reviews))]\n",
    "validation_X = padded_reviews[int(train_val_split*len(padded_reviews)):]\n",
    "validation_y = encoded_label_list[int(train_val_split*len(padded_reviews)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If while training, you get a runtime error that says: \"RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long\".\n",
    "## simply uncomment run the following lines of code additionally\n",
    "# train_X = train_X.astype('int64')\n",
    "# train_y = train_y.astype('int64')\n",
    "# validation_X = validation_X.astype('int64')\n",
    "# validation_y = validation_y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate torch datasets\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_X).to(device), torch.from_numpy(train_y).to(device))\n",
    "validation_dataset = TensorDataset(torch.from_numpy(validation_X).to(device), torch.from_numpy(validation_y).to(device))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "# torch dataloaders (shuffle data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Input size:  torch.Size([32, 512])\n",
      "Example Input:\n",
      " tensor([[    0,     0,     0,  ...,     1,   875,   520],\n",
      "        [    0,     0,     0,  ...,   482,   800,  1794],\n",
      "        [    0,     0,     0,  ...,     3,  1285, 70251],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,     4,     1,  1374],\n",
      "        [    0,     0,     0,  ...,     2,  8268, 17117],\n",
      "        [    0,     0,     0,  ...,  6429,   271,   116]])\n",
      "\n",
      "Example Output size:  torch.Size([32])\n",
      "Example Output:\n",
      " tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# get a batch of train data\n",
    "train_data_iter = iter(train_dataloader)\n",
    "X_example, y_example = train_data_iter.next()\n",
    "print('Example Input size: ', X_example.size()) # batch_size, seq_length\n",
    "print('Example Input:\\n', X_example)\n",
    "print()\n",
    "print('Example Output size: ', y_example.size()) # batch_size\n",
    "print('Example Output:\\n', y_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dimension, embedding_dimension, hidden_dimension, output_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(input_dimension, embedding_dimension)  \n",
    "        self.rnn_layer = nn.RNN(embedding_dimension, hidden_dimension, num_layers=1)\n",
    "        self.fc_layer = nn.Linear(hidden_dimension, output_dimension)\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        # sequence shape = (sequence_length, batch_size)\n",
    "        embedding = self.embedding_layer(sequence)  \n",
    "        # embedding shape = [sequence_length, batch_size, embedding_dimension]\n",
    "        output, hidden_state = self.rnn_layer(embedding)\n",
    "        # output shape = [sequence_length, batch_size, hidden_dimension]\n",
    "        # hidden_state shape = [1, batch_size, hidden_dimension]\n",
    "        final_output = self.fc_layer(hidden_state[-1,:,:].squeeze(0))      \n",
    "        return final_output\n",
    "    \n",
    "input_dimension = len(vocab_to_token)+1 # +1 to account for padding\n",
    "embedding_dimension = 100\n",
    "hidden_dimension = 32\n",
    "output_dimension = 1\n",
    "\n",
    "rnn_model = RNN(input_dimension, embedding_dimension, hidden_dimension, output_dimension)\n",
    "\n",
    "optim = torch.optim.Adam(rnn_model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "rnn_model = rnn_model.to(device)\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Returns 0-1 accuracy for the given set of predictions and ground truth\n",
    "    \"\"\"\n",
    "    # round predictions to either 0 or 1\n",
    "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
    "    success = (rounded_predictions == ground_truth).float() #convert into float for division \n",
    "    accuracy = success.sum() / len(success)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optim, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for sequence, sentiment in dataloader:\n",
    "        optim.zero_grad()     \n",
    "        preds = model(sequence.T).squeeze()\n",
    "        \n",
    "        loss_curr = loss_func(preds, sentiment)\n",
    "        accuracy_curr = accuracy_metric(preds, sentiment)\n",
    "        \n",
    "        loss_curr.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loss += loss_curr.item()\n",
    "        accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(dataloader), accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequence, sentiment in dataloader:\n",
    "            \n",
    "            preds = model(sequence.T).squeeze()\n",
    "            \n",
    "            loss_curr = loss_func(preds, sentiment)   \n",
    "            accuracy_curr = accuracy_metric(preds, sentiment)\n",
    "\n",
    "            loss += loss_curr.item()\n",
    "            accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(dataloader), accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1 | time elapsed: 136.13723397254944s\n",
      "training loss: 0.627 | training accuracy: 66.23%\n",
      "validation loss: 1.048 |  validation accuracy: 19.65%\n",
      "\n",
      "epoch number: 2 | time elapsed: 150.36637210845947s\n",
      "training loss: 0.533 | training accuracy: 73.80%\n",
      "validation loss: 0.858 |  validation accuracy: 54.43%\n",
      "\n",
      "epoch number: 3 | time elapsed: 186.54570603370667s\n",
      "training loss: 0.438 | training accuracy: 80.39%\n",
      "validation loss: 0.551 |  validation accuracy: 78.56%\n",
      "\n",
      "epoch number: 4 | time elapsed: 178.38556694984436s\n",
      "training loss: 0.383 | training accuracy: 83.26%\n",
      "validation loss: 0.915 |  validation accuracy: 57.72%\n",
      "\n",
      "epoch number: 5 | time elapsed: 184.10346102714539s\n",
      "training loss: 0.334 | training accuracy: 86.46%\n",
      "validation loss: 1.001 |  validation accuracy: 56.94%\n",
      "\n",
      "epoch number: 6 | time elapsed: 180.75322008132935s\n",
      "training loss: 0.299 | training accuracy: 88.33%\n",
      "validation loss: 1.164 |  validation accuracy: 54.97%\n",
      "\n",
      "epoch number: 7 | time elapsed: 189.0122902393341s\n",
      "training loss: 0.266 | training accuracy: 89.62%\n",
      "validation loss: 1.133 |  validation accuracy: 60.51%\n",
      "\n",
      "epoch number: 8 | time elapsed: 199.3309519290924s\n",
      "training loss: 0.198 | training accuracy: 92.92%\n",
      "validation loss: 0.971 |  validation accuracy: 66.19%\n",
      "\n",
      "epoch number: 9 | time elapsed: 185.76586294174194s\n",
      "training loss: 0.315 | training accuracy: 87.93%\n",
      "validation loss: 0.950 |  validation accuracy: 62.34%\n",
      "\n",
      "epoch number: 10 | time elapsed: 188.91670608520508s\n",
      "training loss: 0.193 | training accuracy: 93.08%\n",
      "validation loss: 1.042 |  validation accuracy: 62.71%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    time_start = time.time()\n",
    "    \n",
    "    training_loss, train_accuracy = train(rnn_model, train_dataloader, optim, loss_func)\n",
    "    validation_loss, validation_accuracy = validate(rnn_model, validation_dataloader, loss_func)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_delta = time_end - time_start  \n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        torch.save(rnn_model.state_dict(), 'rnn_model.pt')\n",
    "    \n",
    "    print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
    "    print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
    "    print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_inference(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    # text transformations\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([c for c in sentence if c not in punctuation])\n",
    "    tokenized = [vocab_to_token.get(token, 0) for token in sentence.split()]\n",
    "    tokenized = np.pad(tokenized, (512-len(tokenized), 0), 'constant')\n",
    "    \n",
    "    # model inference\n",
    "    model_input = torch.LongTensor(tokenized).to(device)\n",
    "    model_input = model_input.unsqueeze(1)\n",
    "    pred = torch.sigmoid(model(model_input))\n",
    "    \n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05216024070978165\n",
      "0.17682921886444092\n",
      "0.7510029077529907\n",
      "0.9689022898674011\n",
      "0.9829260110855103\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_inference(rnn_model, \"This film is horrible\"))\n",
    "print(sentiment_inference(rnn_model, \"Director tried too hard but this film is bad\"))\n",
    "print(sentiment_inference(rnn_model, \"Decent movie, although could be shorter\"))\n",
    "print(sentiment_inference(rnn_model, \"This film will be houseful for weeks\"))\n",
    "print(sentiment_inference(rnn_model, \"I loved the movie, every part of it\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
